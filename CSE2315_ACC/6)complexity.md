# Complexity

---

# 1. Introduction to Complexity Theory
So far, we have learnt that problems are just languages. These problems can be solved, or in other words,
these languages can be recognised by DFAs, NFAs, GNFAs, PDAs, DTMs, and NDTMs.
We also have seen that some problems have no solutions, that is, no Turing Machine can decide them (undecidable).

From now, we will have a look at:
- How hard are these decidable problems?
- What makes a problem hard or easy?
- What are the hardest problems we know of?

## Complexity of a problem
> The complexity of a problem is the worst-case complexity of 
> the best algorithm for the problem, when executed on a pre-determined machine model.
> <br><br>
> A is a best algorithm for X if for every algorithm B for X and for all n it holds that T_A(n) <= T_B(n).

TIME
> TIME(t(n))<br>
> = {L | L is decided by a 1-tape DTM in O(t(n)) time}<br>
> = set of all languages decided by O(t(n))-1-tape DTMs

## Complexity relationships among models
- Let t(n) be a function, where t(n) >= n.
- Every t(n) time multitape TM has an equivalent O(t^2(n)) time single-tape TM.
- Every t(n) time nondeterministic single-tape TM has an equivalent 2^O(t(n)) time deterministic single-tape TM.


# 2. P
## The class P: Polynomial time problems
- The Strong Church-Turing Thesis (SCTT)
  - Every physically realisable algorithmic process can be simulated on a 1-tape DTM with polynomial overhead
  - The SCTT implies that all "reasonable and conventional" machine models are polynomial equivalent
  - SCTT is accepted, but not proven, with only quantum computing currently believed to be a possible exception to this rule


- Polynomial time
  - An algorithm A with time complexity f(n) is called polynomial-time if f(n) is O(n^c) for some constant c > 0
  - This is sometimes written as: f(n) = n^O(1)
- Exponential time
  - An algorithm A with time complexity f(n) is called exponential-time if f(n) is O(2^(n^c)) for some constant c > 0
  - This is sometimes written as: f(n) = 2^(n^O(1))

## Definition of P
> P <br>
> = U_k>=0 TIME(n^k) <br>
> = {L | L is decided by a DTM in polynomial time} <br>
> = set of all languages decidable in polynomial time

Note that this is a robust complexity class that does not depend on the (deterministic) hardware model used.<br>
Remember that the SCTT only adds polynomial overhead, so that keeps the problem in P.

### Example P problems:
**1\. Let CONNECTED = {\<G> | G is a connected undirected graph}. Consider the algorithm below:**
   - Select the first node of G and mark it.
   - Repeat the following stage until no new nodes are marked:
     - For each node in G, mark it if it is attached by an edge to a node that is already marked.
   - Scan all the nodes of G to determine whether they all are marked. If they are, accept; otherwise, reject.

Show that this language is in P by analysing this algorithm.

- In the first line, first node is selected and marked. This requires a constant time.
- In the second and third line, the nodes are marked until all nodes are marked. This means that if there are n nodes, we scan all edges that are connected to the node.
  - each node has at most n(n-1)/2 edges
  - there are n nodes
  - so in total, this will result into the order of n^3 inspections.
- In line 4, scanning all nodes require n time.
- Therefore this algorithm takes O(n^3) time, which means that it belongs to P.

<br>

**2\. A triangle in an undirected graph is a 3-clique. Show that TRIANGLE ? P, where TRIANGLE = {\<G> | G contains a triangle}.**
- Show that TRIANGLE ε P
- Let A be the TM that decides TRIANGLE in polynomial time. A can be described as follows:
- A = "on input G<V,E> (V denotes the set of vertices in G, and E denotes the set of edges in G)
  - for u,v,w ε V and u<v<w, we enumerate all triples <u,v,w>
  - check whether all three edges (u,v), (v,w), and (w,u) are in E
  - if so, accept. Otherwise reject."
- Analysing this algorithm:
  - enumeration of all triples take O(|V|^3) time (there are |V|^3 possibilities)
  - checking if all three edges belong to E takes O(|E|) time
  - overall time is O(|V|^3 |E|), which is polynomial
  - therefore TRIANGLE ε P

<br>

**3\. Every context-free language is a member of P**
- We know that every CFL is decidable
  - To do so, we gave an algorithm for each CFL that decides it
  - If this algorithm runs in polynomial time, then this theorem follows as a corollary
- Let L be a CFL generated by CFG G that is in Chomsky normal form
  - Any derivation of a string w has 2n-1 steps, where n is the length of w because G is in Chomsky normal form
  - The decider for L works by trying all possible derivation with 2n-1 steps when its input is a string of length n
  - If any of these is a derivation of w, the decider accepts; if not, it rejects
- A quick analysis of derivations with k steps may be exponential in k, but by using dynamic programming, we can solve this in polynomial time
  - Consider the subproblems of determining whether each variable in G generates each substring of w
  - The algorithm enters the solution to this subproblem in n x n table
    - For i <= j, the (i,j)th entry of the table contains the collection of variables that generate the substring w_i w_i+1 ... w_j
    - For i > j, the table entries are unused
  - The algorithm fills in the table entries for each substring of w.
    - First it fills in the entries for the substrings of length 1, then those of length 2, and so on.
    - It uses the entries for the shorter lengths to assist in determining the entries for the longer lengths


- The following algorithm D implements the proof idea:
- D = "On input w = w_1 ... w_n:
  - for w = ε, if S -> ε is a rule, accept; else, reject [w = ε case]
  - for i = 1 to n: [examine each substring of length 1]
    - for each variable A:
      - test whether A -> b is a rule, where b = w_i
      - if so, place A in table (i,i)
  - for l = 2 to n: [l is the length of the substring]
    - for i = 1 to n - l + 1: [i is the start position of the substring]
      - let j = i + l - 1 [j is the end position of the substring]
      - for k = i to j-1: [k is the split position]
        - for each rule A -> BC:
          - if table (i,k) contains B and table(k+1,j) contains C, put A in table (i,j)
  - If S is in table (1,n), accept; else, reject"


- Now analyse D
  - each stage is easily implemented to run in polynomial time
    - the for loop for each variable A runs at most nv times (v is the number of variables in G) => O(n) time
    - the for loop for l = 2 to n runs at most n times
      - for each iteration, the for loop for i = 1 to n - 1 + 1 runs at most n times
        - for each iteration, the for loop for A -> BC runs at most r times (r = number of rules)
          - thus the line inside this for loop runs O(n^3) times
- In total, this algorithm runs in O(n^3) times

<br>

**4\. Show that ALL_DFA is in P**
- ALL_DFA = {\<A> | A is a DFA that recognises Σ*
- E_DFA = {\<A> | A is a DFA and L(A) = ∅} is determined by a TM
  - Let R be the TM that determines ALL_DFA
  - The algorithm of R is as follows:
  - R = "On input \<A>, where A is a DFA
    1. Construct a DFA B that recognises the complement of L(A), by swapping accept and non-accepting states
    2. Run the TM E on input \<B>, where E determines E_DFA
    3. If E accepts, then accept
    4. If E rejects, then reject"
- Clearly R determines ALL_DFA in polynomial time
- Therefore, ALL_DFA is in P




## P = "easy"
- A problem X is tractable (easy) if X ε P.
- A problem X is intractable (hard) if X !ε P.

Tractable = quickly solvable

But why is P easy?
- For problems in P, technological progress (constant speed-up) has a real impact
  - if we have a time complexity O(n^k) and c-speedup, them we can solve problems that are c^(1/k) times the size in the same amount of time as before
- For problems not in P, it doesn't really matter
  - we can solve instances that are log_2(c) bigger
- Exponential time algorithms are (often) brute-force solutions, that do not provide insight into the structure of a problem
- Most polynomial algorithms are algorithms with a low value in the exponent (empirical evidence). Typically k <= 4.


## Closure of P
The class of P is closed under union, concatenation, and complement
- Union
  - Assume two language P1 ε P and P2 ε P. The TM M that accepts P1 U P2 works as follows:
  - M = "on input w:
    1. Check if w ε P1
    2. If not check if w ε P2
    3. Accept w iff P1 or P2 accepts 
    4. if both reject then reject"
  - Since each membership check requires polynomial time, the overall time is polynomial
- Concatenation
  - Assume two language P1 ε P and P2 ε P. The TM M that accepts P1P2 works as follows:
  - M = "on input w of length n:
    1. w can be split into n different ways
    2. for each split:
       1. check if the first substring belongs to P1
       2. check if the second substring belongs to P2
    3. If any split succeeds, then accept. Otherwise reject."
  - Checking all splits and checking the memberships take polynomial time
- Complement
  - Assume a language P1 ε P. The TM M that accepts the complement of P1 works as follows:
  - M = "on input w:
    1. check if w is in P1
    2. accept if it is
    3. reject if it is not"
  - This is clearly taking polynomial time


# 3. NP
## The class NP
Verifier
- A verifier for a language A is an algorithm V, where
  - A = {w | V accepts <w,c> for some string c}
- We measure the time of a verifier only in terms of the length of w, so a polynomial time verifier runs in polynomial time in the length of w
- A language A is polynomially verifiable if it has a polynomial time verifier

NTIME
- NTIME(t(n)) = {L | L is a language decided by an O(t(n)) time NDTM}

## Definition of NP
> NP <br>
> = U_k>=0 NTIME(n^k) <br>
> {L | L is decided by a non-deterministic TM in polynomial time}

In computability theory, DTMs and NDTMs have equal power. However, in complexity theory, we look at the time complexity.
In the previous sections we have seen that O(t(n)) time in NDTM is O(2^(t(n))) time in 1-tape DTM
(since there are log2(n) branches of computations, and trying every possible computation path results in exponential overhead)


# 4. P vs NP
Is P = NP?

- P = the class of languages for which membership can be decided quickly
- NP = the class of languages for which membership can be verified quickly

## P, NP, and sets
A = B <-> (A ⊆ B Λ B ⊆ A)

P ⊆ NP, because:
- Every DTM is a special form of an NDTM
- Verifying a solution for a problem in P in polynomial time is easy, we just run our polynomial time algorithm to find the solution

But we don't know if P = NP.

Assuming that P != NP, we have many questions that is under the class NP - P.

Constructing a solution for a problem in NP - P can be done in exponential time, we don't know how to do it in polynomial time.<br>
We can verify a given solution to an NP problem in polynomial time.



# 5. Karp Reductions
Karp reduction is a type of reductions that:
- is a polynomial-time reduction
- demonstrate that one decision problem can be transformed into another decision problem in polynomial time
- often used to show that a problem is NP-hard or NP-complete. (more on this later)

Idea of Karp reduction:
- Take an instance of one problem. Convert it into an instance of another problem in a way that preserves the "yes" or "no" answer.
  - (I is a yes-instance <-> f(I) is a yes-instance)
- If a Karp reduction can be found between two problems A and B, it means that any algorithm that can efficiently solve problem B can also be used to solve problem A efficiently, as the reduction itself takes polynomial time.


## Definition
> A Karp reduction f:A -> B is a polynomial-time mapping from the instances of A to
> the instances of B such that we can decide every x ε A by deciding f(x) ε B with a decider for B.

We denote this as A <= B, this means:
- A is not essentially harder than B
- A is Karp-reducible to B

## Properties
If X <= Y, then:
1. if Y ε P, then X ε P (P is downwards-closed)
2. if Y ε NP, then X ε NP (NP is downwards-closed)
3. if X ε NP-hard, then Y ε NP-hard

### 1. P is downwards closed
> if X <= Y and Y ε P, then X ε P

Proof
- Let A be an algorithm for Y that decides instances of Y in polynomial time
- Let f be the Karp reduction that maps instances of X to instances of Y
- To prove: there is an algorithm B that decides instances of X in polynomial time.
  - Construct B which 
    - takes an instances x ε X
    - first computes f(x) = y
    - then runs A on y
  - Since the reduction is reliable (yes- and no-instances are preserved) and f is polynomial
  - Thus y is polynomially bound in x (y = x + O(x^c)), and since A runs in polynomial time, B must also be polynomial

### 2. NP is downwards closed
> if X <= Y and Y ε NP, then X ε NP

Proof (only added non-determinsitic from the proof of downward closure of P)
- Let A be a non-deterministic algorithm for Y that decides instances of Y in polynomial time
- Let f be the Karp reduction that maps instances of X to instances of Y
- To prove: there is an algorithm B that decides instances of X in polynomial time.
  - Construct B which
    - takes an instances x ε X
    - first computes f(x) = y
    - then runs A on y
  - Since the reduction is reliable (yes- and no-instances are preserved) and f is polynomial
  - Thus y is polynomially bound in x (y = x + O(x^c)), and since A runs in polynomial time, B must also be polynomial non-deterministic time

### 3. NP-hard
> A problem A is NP-Hard iff for all X ε NP it holds that X <= A <br>
> or in other words, if any problem in NP can be reduced to this problem <br>
> Note: NP-hard problems might not be in NP

> if X ε NP-hard, then Y ε NP-hard

Proof
- Let f be the Karp reduction that maps instances of X to instances of Y
- Let Z be an arbitrary problem from NP
- To prove: Z <= Y
  - Since X ε NP-hard, there is a reduction g from Z to X
  - Thus h: Z -> Y can be constructed by: h(z) = f(g(z)), which is a combination of polynomial time operations and thus a polynomial time reduction
  - Since Z was arbitrarily chosen, this holds for all problems from NP, and therefore Y is NP-hard


## NP-complete
> A language B is NP-complete if it satisfies two conditions: <br>
> 1. B is in NP, and
> 2. every A in NP is polynomial reducible to B, i.e. B is NP-hard

### Polynomial time reducibility
> Polynomial time computable function
> - A function f: Σ* -> Σ* is a polynomial time computable function if some polynomial time TM M exists that halts with just f(w) on its tape, when started on any input w.

> Polynomial time reducible
> - Language A is polynomial time reducible to language B, written A <=_P B, if a polynomial time computable function f: Σ* -> Σ* exists, where for every w:
> - w ε Α <=> f(w) ε B
> - The function f is called the polynomial time reduction of A to B

### Theorem 1. If B is NP-complete and B ε P, then P = NP
This directly follows from the definition of polynomial time reducibility

### Theorem 2. If B is NP-complete and B <=_P C for C in NP, then C is NP-complete
- We know that C is in NP, so we must show that every A in NP is polynomial time reducible to C.
- Because B is NP-complete, every language in NP is polynomial time reducible to B, and B in turns is polynomial time reducible to C
- Polynomial time reductions compose;
  - if A is polynomial time reducible to B and B is polynomial time reducible to C, then A is polynomial time reducible to C
- Hence every language in NP is polynomial time reducible to C